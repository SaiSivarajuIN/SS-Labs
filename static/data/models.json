[
    {
        "id": "mistral",
        "name": "Mistral-7b-v0.3-bnb-4bit-GGUF",
        "repo": "https://huggingface.co/ss-lab/Mistral-7b-v0.3-bnb-4bit-GGUF",
        "details": {
            "Model Size": "7B parameters",
            "Architecture": "Mistral 7B v0.3",
            "Quantization": "Q3_K_M (3.52 GB) / Q4_K_M (4.37 GB)",
            "License": "Apache 2.0"
        },
        "files": [
            "mistral-7b-v0.3.Q3_K_M.gguf",
            "mistral-7b-v0.3.Q4_K_M.gguf"
        ]
    },
    {
        "id": "mistral-nemo",
        "name": "Mistral-Nemo-Instruct-2407-GGUF",
        "repo": "https://huggingface.co/ss-lab/Mistral-Nemo-Instruct-2407-bnb-GGUF",
        "details": {
            "Model Size": "12B parameters",
            "Architecture": "Mistral Nemo Instruct 2407",
            "Quantization": "TQ1_0 (4.99 GB)",
            "License": "Mistral AI Non-Production License"
        },
        "files": [
            "Mistral-Nemo-Instruct-2407.TQ1_0.gguf"
        ]
    },
    {
        "id": "phi",
        "name": "Phi-3.5-mini-instruct-GGUF",
        "repo": "https://huggingface.co/ss-lab/Phi-3.5-mini-instruct-GGUF",
        "details": {
            "Model Size": "3.8B parameters",
            "Architecture": "Phi-3.5 Mini Instruct",
            "Quantization": "Q4_K_M (2.2 GB)",
            "License": "MIT"
        },
        "files": [
            "phi-3.5-mini-instruct.Q4_K_M.gguf"
        ]
    },
    {
        "id": "phi-4k",
        "name": "Phi-3-mini-4k-instruct-GGUF",
        "repo": "https://huggingface.co/ss-lab/Phi-3-mini-4k-instruct-GGUF",
        "details": {
            "Model Size": "3.8B parameters",
            "Architecture": "Phi-3 Mini 4k Instruct",
            "Quantization": "Q4_K_M (2.2 GB) / Q2_0 (1.1 GB)",
            "License": "MIT"
        },
        "files": [
            "Phi-3-mini-4k-instruct-q4_K_M.gguf",
            "Phi-3-mini-4k-instruct-tq2_0.gguf"
        ]
    },
    {
        "id": "llama3",
        "name": "Llama-3-8b-bnb-4bit-GGUF",
        "repo": "https://huggingface.co/ss-lab/Llama-3-8b-bnb-4bit-GGUF",
        "details": {
            "Model Size": "8B parameters",
            "Architecture": "Llama 3",
            "Quantization": "Q4_K_M (~5.0 GB)",
            "License": "Llama 3 Community License"
        },
        "files": [
            "llama-3-8b.Q4_K_M.gguf"
        ]
    },
    {
        "id": "llama3.2",
        "name": "Llama-3.2-1B-Instruct-GGUF",
        "repo": "https://huggingface.co/ss-lab/Llama-3.2-1B-Instruct-bnb-4bit-GGUF",
        "details": {
            "Model Size": "1B parameters",
            "Architecture": "Llama 3.2",
            "Quantization": "Q3_K_M (~0.6 GB)",
            "License": "Llama 3 Community License"
        },
        "files": [
            "Llama-3.2-1B-Instruct.Q3_K_M.gguf"
        ]
    },
    {
        "id": "falcon",
        "name": "Falcon-H1-0.5B-Instruct-GGUF",
        "repo": "https://huggingface.co/ss-lab/Falcon-H1-0.5B-Instruct-GGUF",
        "details": {
            "Model Size": "0.5B parameters",
            "Architecture": "Falcon H1",
            "Quantization": "Q8_0 (~0.5 GB)",
            "License": "Apache 2.0"
        },
        "files": [
            "Falcon-H1-0.5B-Instruct-Q8_0.gguf"
        ]
    },
    {
        "id": "qwen",
        "name": "Qwen3-4B-Instruct-2507-GGUF",
        "repo": "https://huggingface.co/ss-lab/Qwen3-4B-Instruct-2507-GGUF",
        "details": {
            "Model Size": "4B parameters",
            "Architecture": "Qwen 3",
            "Quantization": "Q8_0 (4.28 GB)",
            "License": "Apache 2.0"
        },
        "files": [
            "Qwen3-4B-Instruct-2507-Q8_0.gguf"
        ]
    },
    {
        "id": "lfm",
        "name": "LFM2-2.6B-GGUF",
        "repo": "https://huggingface.co/ss-lab/LFM2-2.6B-GGUF",
        "details": {
            "Model Size": "2.6B parameters",
            "Architecture": "LFM 2",
            "Quantization": "Q4_0 (1.48 GB)",
            "License": "Apache 2.0"
        },
        "files": [
            "LFM2-2.6B-Q4_0.gguf"
        ]
    }
]
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SS Labs ‚Äî Hugging Face Models Documentation</title>
    <link rel="stylesheet" href="../static/styles.css">
    <link rel="icon" href="../static/logo.png" type="image/png">
    <style>
        body {
            margin: 0;
            padding-top: 60px; /* Space for the fixed header */
        }
        .menu-toggle {
            display: none; /* Hidden by default */
            cursor: pointer;
            margin-right: 15px;
        }
        .page-header {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 60px;
            background-color: #ffffff;
            border-bottom: 1px solid #dee2e6;
            display: flex;
            align-items: center;
            padding: 0 20px;
            box-sizing: border-box;
            z-index: 1000;
        }
        .page-header h1 {
            font-size: 1.2em;
            margin: 0;
        }
        .page-header .logo {
            height: 40px;
            width: auto;
            margin-right: 15px;
            vertical-align: middle;
        }
        .roadmap {
            position: fixed;
            top: 60px; /* Position below the header */
            left: 0;
            height: calc(100vh - 60px); /* Full height minus header */
            width: 240px; /* Sidebar width */
            background-color: #f8f9fa;
            border-right: 1px solid #dee2e6;
            padding: 20px;
            overflow-y: auto;
            box-sizing: border-box;
            z-index: 900;
            transition: transform 0.3s ease-in-out;
        }
        .roadmap ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }
        .roadmap li a {
            display: block;
            padding: 4px 0;
            color: #222; /* Match body text color */
        }
        .roadmap li:hover {
            background-color: #e9ecef; /* Light gray highlight */
            border-radius: 4px; /* Optional: adds rounded corners */
        }
        .roadmap li a:hover {
            text-decoration: none; /* Remove underline on hover */
            color: #232527; /* Optional: Add a color change for hover feedback */
        }
        .main-content a {
            color: inherit; /* Use the parent text color */
            text-decoration: underline; /* Keep links underlined for accessibility */
        }
        .main-content a:hover {
            text-decoration: none; /* Remove underline on hover for a clean look */
        }
        .main-content {
            margin-left: 240px; /* Same as sidebar width */
            max-width: 900px; /* Set a max-width for readability */
            padding: 20px 40px; /* Add some horizontal padding */
            margin: 0 auto 0 240px; /* Center the content relative to the remaining space */
            transition: margin-left 0.3s ease-in-out;
        }

        /* Responsive styles for mobile */
        @media (max-width: 768px) {
            .menu-toggle {
                display: block; /* Show hamburger menu */
            }
            .page-header h1 {
                font-size: 1.2em;
            }
            .roadmap {
                transform: translateX(-100%); /* Hide sidebar off-screen */
                z-index: 1100; /* Ensure it's above main content but below header */
            }
            .roadmap.open {
                transform: translateX(0); /* Show sidebar */
            }
            .main-content {
                margin-left: 0; /* Content takes full width */
                width: 100%;
                max-width: none; /* Remove max-width on mobile */
                padding: 20px;
                box-sizing: border-box;
            }
            /* Remove logo from sidebar on mobile to avoid duplication */
            .roadmap .logo {
                display: none;
            }
            .content-wrapper {
                padding: 0; /* Remove padding on mobile as main-content has it */
            }
        }

        /* Add scroll margin to anchor targets to account for the fixed header */
        h2[id] {
            scroll-margin-top: 80px; /* Adjust this value to match your header's height + some padding */
        }
        .spacer {
            scroll-margin-top: 80px;
        }
    </style>
</head>
<body>
    <header class="page-header">
        <div class="menu-toggle" id="menu-toggle">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M4 6H20M4 12H20M4 18H20" stroke="#333" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
        </div>
        <img src="../static/logo.png" alt="SS Labs Logo" class="logo">
        <h1>SS Labs ‚Äî Hugging Face Models Documentation</h1>
    </header>

    <!-- Roadmap Navigation -->
    <nav class="roadmap" id="roadmap">
        <h3>Roadmap</h3>
        <ul>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#exaone">EXAONE-4.0-1.2B-GGUF</a></li>
            <li><a href="#mistral">Mistral-7B-v0.3-GGUF</a></li>
            <li><a href="#phi">Phi-3.5-mini-instruct-GGUF</a></li>
            <li><a href="#gemma">Gemma-7B-GGUF</a></li>
            <li><a href="#llama3">Llama-3-8B-GGUF</a></li>
            <li><a href="#performance">Model Comparison</a></li>
            <li><a href="#finetuning">Fine-tuning</a></li>
            <li><a href="#about">About SS Labs</a></li>
            <li><a href="#references">References</a></li>
        </ul>
    </nav>
    
    <div class="main-content">
        <div class="content-wrapper">
            <!--- Main Content -->
            <div class="spacer" id="overview">
                <p>Welcome to <b>SS Labs</b>, a research and deployment group focused on efficient LLM conversions, 
                    fine-tuning, and GGUF model optimization for edge and cloud inference.
                </p>
                <blockquote><a href="https://huggingface.co/ss-lab" target="_blank">View on Hugging Face</a></blockquote>
            </div>

            <!-- Model Overview -->
            <h2>Overview</h2>
            <ul>
                <li><b>EXAONE-4.0-1.2B-GGUF</b> ‚Äî a lightweight, multilingual conversational model.</li>
                <li><b>Mistral-7B-v0.3-GGUF</b> ‚Äî a finetuned version of Mistral 7B optimized for GGUF-based inference.</li>
                <li><b>Phi-3.5-mini-instruct-GGUF</b> ‚Äî a lightweight, high-performance conversational model.</li>
                <li><b>Gemma-7B-GGUF</b> ‚Äî a lightweight, high-performance model from Google.</li>
                <li><b>Llama-3-8B-GGUF</b> ‚Äî a powerful, instruction-tuned model from Meta.</li>
            </ul>
            
            <!-- Compatibility Note -->
            <p>All models are compatible with <b>llama.cpp</b>, <b>Unsloth</b>, and <b>T4 GPUs</b>.</p>

            <!-- Model Details -->
            <!-- EXAONE-4.0-1.2B-GGUF Section -->
            <h2 id="exaone">EXAONE-4.0-1.2B-GGUF</h2>
            <p><b>Repository:</b> <a href="https://huggingface.co/ss-lab/EXAONE-4.0-1.2B-GGUF" target="_blank">hf.co/ss-lab/EXAONE-4.0-1.2B-GGUF</a></p>

            <h3>Details</h3>
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>Model Size</td><td>1.2B parameters</td></tr>
                <tr><td>Architecture</td><td>EXAONE 4.0</td></tr>
                <tr><td>Quantization</td><td>Q4_K_M (812 MB) / Q8_0 (1.36 GB)</td></tr>
                <tr><td>Languages</td><td>English, Korean</td></tr>
                <tr><td>License</td><td>Apache 2.0</td></tr>
            </table>

            <h3>üìÅ Available Model Files</h3>
            <pre>EXAONE-4.0-1.2B.Q4_K_M.gguf
EXAONE-4.0-1.2B.Q8_0.gguf</pre>

            <!-- Mistral-7B-v0.3-GGUF Section -->
            <h2 id="mistral">Mistral-7B-v0.3-GGUF</h2>
            <p><b>Repository:</b> <a href="https://huggingface.co/ss-lab/Mistral-7b-v0.3-GGUF" target="_blank">hf.co/ss-lab/Mistral-7b-v0.3-GGUF</a></p>

            <h3>Details</h3>
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>Model Size</td><td>7B parameters</td></tr>
                <tr><td>Architecture</td><td>Mistral 7B v0.3</td></tr>
                <tr><td>Quantization</td><td>Q3_K_M (3.52 GB) / Q4_K_M (4.37 GB)</td></tr>
                <tr><td>License</td><td>Apache 2.0</td></tr>
            </table>

            <h3>üìÅ Available Model Files</h3>
            <pre>mistral-7b-v0.3.Q3_K_M.gguf
mistral-7b-v0.3.Q4_K_M.gguf</pre>

            <!-- Phi-3.5-mini-instruct.GGUF Section -->
            <h2 id="phi">Phi-3.5-mini-instruct-GGUF</h2>
            <p><b>Repository:</b> <a href="https://huggingface.co/ss-lab/Phi-3.5-mini-instruct-GGUF" target="_blank">hf.co/ss-lab/Phi-3.5-mini-instruct-GGUF</a></p>

            <h3>Details</h3>
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>Model Size</td><td>3.8B parameters</td></tr>
                <tr><td>Architecture</td><td>Phi-3.5 Mini Instruct</td></tr>
                <tr><td>Quantization</td><td>Q4_K_M (2.2 GB)</td></tr>
                <tr><td>License</td><td>MIT</td></tr>
            </table>

            <h3>üìÅ Available Model Files</h3>
            <pre>phi-3.5-mini-instruct.Q4_K_M.gguf</pre>

            <!-- Gemma-7B-GGUF Section -->
            <h2 id="gemma">Gemma-7B-GGUF</h2>
            <p><b>Repository:</b> <a href="https://huggingface.co/ss-lab/Gemma-7B-GGUF" target="_blank">hf.co/ss-lab/Gemma-7B-GGUF</a></p>

            <h3>Details</h3>
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>Model Size</td><td>7B parameters</td></tr>
                <tr><td>Architecture</td><td>Gemma</td></tr>
                <tr><td>Quantization</td><td>Q4_K_M (4.37 GB)</td></tr>
                <tr><td>License</td><td>Gemma Terms of Use</td></tr>
            </table>

            <h3>üìÅ Available Model Files</h3>
            <pre>gemma-7b.Q4_K_M.gguf</pre>

            <!-- Llama-3-8B-GGUF Section -->
            <h2 id="llama3">Llama-3-8B-GGUF</h2>
            <p><b>Repository:</b> <a href="https://huggingface.co/ss-lab/Llama-3-8B-GGUF" target="_blank">hf.co/ss-lab/Llama-3-8B-GGUF</a></p>

            <h3>Details</h3>
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>Model Size</td><td>8B parameters</td></tr>
                <tr><td>Architecture</td><td>Llama 3</td></tr>
                <tr><td>Quantization</td><td>Q4_K_M (~5.0 GB)</td></tr>
                <tr><td>License</td><td>Llama 3 Community License</td></tr>
            </table>

            <h3>üìÅ Available Model Files</h3>
            <pre>llama-3-8b.Q4_K_M.gguf</pre>

            <!-- Performance Overview -->
            <h2 id="performance">Model Comparison</h2>
            <table>
                <tr><th>Model</th><th>Params</th><th>Format</th><th>Quant</th><th>GPU RAM (min)</th></tr>
                <tr><td>EXAONE 4.0</td><td>1.2B</td><td>GGUF</td><td>Q4 / Q8</td><td>812 MB ‚Äì 1.36 GB</td></tr>
                <tr><td>Llama 3</td><td>8B</td><td>GGUF</td><td>Q4</td><td>~5.0 GB</td></tr>
                <tr><td>Phi-3.5 Mini</td><td>3.8B</td><td>GGUF</td><td>Q4</td><td>~2.2 GB</td></tr>
                <tr><td>Mistral 7B</td><td>7B</td><td>GGUF</td><td>Q3 / Q4</td><td>3.52 GB ‚Äì 4.37 GB</td></tr>
                <tr><td>Gemma 7B</td><td>7B</td><td>GGUF</td><td>Q4</td><td>~4.37 GB</td></tr>
            </table>

            <!-- Fine-tuning Section -->
            <h2 id="finetuning">Fine-tuning with Unsloth</h2>
            <p>
                We specialize in creating efficient fine-tuning workflows using <strong>Unsloth</strong>, which enables rapid training on consumer-grade hardware like T4 GPUs. Our methods are optimized for memory efficiency without sacrificing performance, making it possible to fine-tune models on local machines or free cloud instances.
            </p>
            <p>
                Our primary fine-tuning guide is available as a Jupyter notebook. It covers the end-to-end process for adapting models to your specific needs. Explore our step-by-step guide to start fine-tuning your own models.
            </p>
            <p>‚û°Ô∏è <a href="https://github.com/SaiSivarajuIN/SS-Labs/tree/main/Fine-tuning" target="_blank">View Fine-tuning Notebook on GitHub</a></p>

            <!-- About Section -->
            <div class="spacer">
                <h2 id="about">About SS Labs</h2>

                <p><b>SS Labs</b> focuses on converting open LLMs to efficient GGUF formats, 
                    fine-tuning for local inference, and building multilingual text generation models.
                </p>
                <blockquote>‚ÄúEfficiency meets accessibility ‚Äî one model at a time.‚Äù</blockquote>
            </div>

            <!-- References Section -->
            <h2 id="references">References</h2>
            <ul>
                <li><a href="https://huggingface.co/ss-lab" target="_blank">SS Labs on Hugging Face</a></li>
                <li><a href="https://docs.unsloth.ai/" target="_blank">Unsloth Doc</a></li>
            </ul>

            <!-- Footer -->
            <footer>
                <p>¬© 2024 SS Labs. All rights reserved.</p>
            </footer>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const menuToggle = document.getElementById('menu-toggle');
            const roadmap = document.getElementById('roadmap');
            const roadmapLinks = roadmap.querySelectorAll('a');

            menuToggle.addEventListener('click', function () {
                roadmap.classList.toggle('open');
            });

            // Close sidebar when a link is clicked
            roadmapLinks.forEach(link => link.addEventListener('click', () => roadmap.classList.remove('open')));
        });
    </script>
</body>
</html>
